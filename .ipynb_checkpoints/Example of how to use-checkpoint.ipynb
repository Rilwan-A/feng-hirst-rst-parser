{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of how to use "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If this code is not run from within the directory feng_hirst_rst_parser, then the '1a. neccessary imports' section below must be used\n",
    "\n",
    "### If it is run from within the directory 'feng_hirst_rst_parser', then the '1b. necessary imports' section must be used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1a.  Neccessary Imports if outside feng_hirst_rst_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dir_feng_hirst_rst_parser' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-7e4a0098959f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmp2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Enter path of feng_hirst_rst_parser directory\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#mp2 =  \"./DockerImages/feng_hirst_rst_parser\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdir_feng_hirst_rst_parser\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mmp3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmp2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"src\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mmp4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmp2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dir_feng_hirst_rst_parser' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "mp2 = \"Enter path of feng_hirst_rst_parser directory\"\n",
    "#mp2 =  \"./DockerImages/feng_hirst_rst_parser\"\n",
    "mp3 = os.path.join(mp2,\"src\")\n",
    "mp4 = os.path.join(mp2,\"model\")\n",
    "modules_paths = [mp2, mp3, mp4]\n",
    "\n",
    "for path_ in modules_paths:\n",
    "    if path_ not in sys.path:\n",
    "        sys.path.append(path_)\n",
    "\n",
    "from src import parser_wrapper3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1b. Necessary imports if inside feng_hirst_rst_parser directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', 'home', 'akann1w0w1ck', 'mastering-conversation', 'rl_conv', 'pretrain', 'DockerImages', 'feng_hirst_rst_parser']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "mp2 = \".\"\n",
    "mp3 = os.path.join(mp2,\"src\")\n",
    "mp4 = os.path.join(mp2,\"model\")\n",
    "modules_paths = [mp3, mp4]\n",
    "\n",
    "for path_ in modules_paths:\n",
    "    if path_ not in sys.path:\n",
    "        sys.path.append(path_)\n",
    "\n",
    "from src import parser_wrapper3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Gather list of text to be parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input your texts into a list of lists. My parser operates on the text in batches. \n",
    "# So each sublist contains one batch of text, that will be parsed as a batch\n",
    "\n",
    "li_li_utt = [ [\"I believe in God, but I am having doubts about the stories in the Bible.\",\n",
    "              \"I went to the shop after I finished my last class at school\"] ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### 2.b If you have multiple large texts, Then input them in seperate sublists"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Example: case where you have very long texts. Then ensure that each sublist has at most 10 long texts. \n",
    "    This number varies based on the ability of your computer. This prevents memory issues which can occur during parsing with multiple simultaneous processes by using multiprocessing.pool().\n",
    "    \n",
    "li_li_utt = [ \n",
    "               [list containing 10 long texts of tokenization length 200],\n",
    "                [list containing 10 long texts of tokenization length 200]\n",
    "            ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3a. Parse only EDU structure from texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The returned object is just a list containing all the texts with the EDU parsing. \n",
    "\n",
    "li_edu_parsed = parser_wrapper3.main( json_li_li_utterances= json.dumps( li_li_utt ), \n",
    "                                                skip_parsing=True, #<---- skip_parsing=True to just get EDU\n",
    "                                                   redirect_output=True)\n",
    "#li_edu_parsed = sum( li_li_edu_parsed,[] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['I', 'believe', 'in', 'God', ',', 'EDU_BREAK', 'but', 'I', 'am', 'having', 'doubts', 'about', 'the', 'stories', 'in', 'the', 'Bible', '.', 'EDU_BREAK'], ['I', 'went', 'to', 'the', 'shop', 'EDU_BREAK', 'after', 'I', 'finished', 'my', 'last', 'class', 'at', 'school', 'EDU_BREAK']]\n"
     ]
    }
   ],
   "source": [
    "print(li_li_edu_parsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3b. Parse full RST structure from texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The returned object is a list of lists, where each sublist contains parsed batches of input text\n",
    "\n",
    "li_li_rst_parsed = parser_wrapper3.main( json_li_li_utterances= json.dumps( li_li_utt ), \n",
    "                                                skip_parsing=False,#<---- skip_parsing=False to just get RST\n",
    "                                                   redirect_output=True)\n",
    "\n",
    "li_rst_parsed = sum( li_li_rst_parsed, [] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['{Contrast[S][N]\\n  _!I believe in God ,!_\\n  _!but I am having doubts about the stories in the Bible . <P>!_}',\n",
       " '{Temporal[N][S]\\n  _!I went to the shop!_\\n  _!after I finished my last class at school <P>!_}']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "li_rst_parsed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
